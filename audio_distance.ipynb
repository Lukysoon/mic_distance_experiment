{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d33e128",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b57ed56c",
   "metadata": {},
   "source": [
    "## 1. Import knihoven a základní nastavení"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a89d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Knihovny načteny\n",
      "Librosa version: 0.11.0\n",
      "XGBoost version: 3.0.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import librosa.display\n",
    "import pandas as pd\n",
    "from scipy import signal, stats\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import os\n",
    "from IPython.display import Audio, display, HTML\n",
    "from tqdm.notebook import tqdm\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFeatureExtractor:\n",
    "    \"\"\"Extrakce features pro detekci vzdálenosti od mikrofonu\"\"\"\n",
    "    \n",
    "    def __init__(self, sr=16000, n_mfcc=13):\n",
    "        self.sr = sr\n",
    "        self.n_mfcc = n_mfcc\n",
    "        \n",
    "    def extract_features(self, audio_input):\n",
    "        \"\"\"\n",
    "        Extrahuje všechny features z audio souboru nebo audio dat\n",
    "        \n",
    "        Args:\n",
    "            audio_input: cesta k audio souboru NEBO numpy array s audio daty\n",
    "            \n",
    "        Returns:\n",
    "            dict: slovník s features\n",
    "        \"\"\"\n",
    "        # Načtení audia\n",
    "        if isinstance(audio_input, str):\n",
    "            y, sr = librosa.load(audio_input, sr=self.sr)\n",
    "        else:\n",
    "            y = audio_input\n",
    "            sr = self.sr\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # 1. ENERGETICKÉ FEATURES\n",
    "        features.update(self._extract_energy_features(y))\n",
    "        \n",
    "        # 2. SPEKTRÁLNÍ FEATURES\n",
    "        features.update(self._extract_spectral_features(y, sr))\n",
    "        \n",
    "        # 3. CLARITY FEATURES\n",
    "        features.update(self._extract_clarity_features(y, sr))\n",
    "        \n",
    "        # 4. ROOM ACOUSTICS FEATURES\n",
    "        features.update(self._extract_room_features(y, sr))\n",
    "        \n",
    "        # 5. MFCC FEATURES (pro dodatečnou informaci)\n",
    "        features.update(self._extract_mfcc_features(y, sr))\n",
    "        \n",
    "        return features\n",
    "\n",
    "class AudioPreprocessor:\n",
    "    \"\"\"Preprocessing audio souborů - rozdělení na chunky\"\"\"\n",
    "    \n",
    "    def __init__(self, chunk_duration=3.0, overlap=0.5, sr=16000, \n",
    "                 min_silence_duration=0.1, silence_threshold=-40):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            chunk_duration: délka jednoho chunku v sekundách\n",
    "            overlap: překryv mezi chunky (0.0 = žádný, 0.5 = 50% překryv)\n",
    "            sr: sample rate\n",
    "            min_silence_duration: minimální délka ticha v sekundách pro detekci\n",
    "            silence_threshold: práh pro detekci ticha v dB\n",
    "        \"\"\"\n",
    "        self.chunk_duration = chunk_duration\n",
    "        self.overlap = overlap\n",
    "        self.sr = sr\n",
    "        self.min_silence_duration = min_silence_duration\n",
    "        self.silence_threshold = silence_threshold\n",
    "    \n",
    "    def split_into_chunks(self, audio_path, remove_silence=True):\n",
    "        \"\"\"\n",
    "        Rozdělí audio soubor na chunky\n",
    "        \n",
    "        Args:\n",
    "            audio_path: cesta k audio souboru\n",
    "            remove_silence: zda odstraňovat tiché části\n",
    "            \n",
    "        Returns:\n",
    "            list: seznam audio chunků (numpy arrays)\n",
    "            list: seznam časových pozic začátku každého chunku\n",
    "        \"\"\"\n",
    "        # Načtení audia\n",
    "        y, sr = librosa.load(audio_path, sr=self.sr)\n",
    "        \n",
    "        # Odstranění ticha pokud je požadováno\n",
    "        if remove_silence:\n",
    "            y = self._remove_silence(y, sr)\n",
    "        \n",
    "        # Pokud je audio příliš krátké, vrátíme ho celé\n",
    "        if len(y) < self.chunk_duration * sr:\n",
    "            return [y], [0.0]\n",
    "        \n",
    "        # Výpočet parametrů pro chunking\n",
    "        chunk_samples = int(self.chunk_duration * sr)\n",
    "        hop_samples = int(chunk_samples * (1 - self.overlap))\n",
    "        \n",
    "        chunks = []\n",
    "        timestamps = []\n",
    "        \n",
    "        # Rozdělení na chunky\n",
    "        for start in range(0, len(y) - chunk_samples + 1, hop_samples):\n",
    "            end = start + chunk_samples\n",
    "            chunk = y[start:end]\n",
    "            \n",
    "            # Kontrola, zda chunk není příliš tichý\n",
    "            if self._is_valid_chunk(chunk):\n",
    "                chunks.append(chunk)\n",
    "                timestamps.append(start / sr)\n",
    "        \n",
    "        # Pokud máme zbytek, přidáme ho jako poslední chunk (s paddingem)\n",
    "        if len(chunks) > 0:  # Pouze pokud už máme nějaké chunky\n",
    "            remainder = len(y) % hop_samples\n",
    "            if remainder > sr * 0.5:  # Pokud je zbytek delší než 0.5s\n",
    "                last_chunk = y[-chunk_samples:]\n",
    "                if len(last_chunk) < chunk_samples:\n",
    "                    # Padding\n",
    "                    last_chunk = np.pad(last_chunk, (0, chunk_samples - len(last_chunk)))\n",
    "                if self._is_valid_chunk(last_chunk):\n",
    "                    chunks.append(last_chunk)\n",
    "                    timestamps.append((len(y) - chunk_samples) / sr)\n",
    "        \n",
    "        return chunks, timestamps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd0c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDistanceClassifier:\n",
    "    def __init__(self, model_type='xgboost', n_classes=2):\n",
    "        self.model_type = model_type\n",
    "        self.n_classes = n_classes\n",
    "        self.feature_extractor = AudioFeatureExtractor()\n",
    "        self.preprocessor = AudioPreprocessor()\n",
    "        self.scaler = StandardScaler()\n",
    "        self.model = None\n",
    "        self.feature_importance = None\n",
    "        self.class_names = None\n",
    "        \n",
    "    def prepare_dataset(self, audio_files, labels, use_chunks=True, augment=False):\n",
    "        \"\"\"\n",
    "        Připraví dataset z audio souborů\n",
    "        \n",
    "        Args:\n",
    "            audio_files: seznam cest k audio souborům\n",
    "            labels: seznam labelů\n",
    "            use_chunks: zda rozdělit soubory na chunky\n",
    "            augment: zda použít data augmentaci\n",
    "            \n",
    "        Returns:\n",
    "            X: feature matrix\n",
    "            y: labels\n",
    "            feature_names: názvy features\n",
    "        \"\"\"\n",
    "        if use_chunks:\n",
    "            # Preprocessing - rozdělení na chunky\n",
    "            chunk_data, chunk_labels = self.preprocessor.preprocess_dataset(\n",
    "                audio_files, labels, augment=augment\n",
    "            )\n",
    "            \n",
    "            # Extrakce features z chunků\n",
    "            features_list = []\n",
    "            valid_labels = []\n",
    "            \n",
    "            print(\"\\nExtracting features from chunks...\")\n",
    "            for idx, (chunk_info, label) in enumerate(zip(chunk_data, chunk_labels)):\n",
    "                try:\n",
    "                    # Extrakce features přímo z audio dat (ne ze souboru)\n",
    "                    features = self.feature_extractor.extract_features(chunk_info['chunk_audio'])\n",
    "                    features_list.append(features)\n",
    "                    valid_labels.append(label)\n",
    "                    \n",
    "                    if (idx + 1) % 100 == 0:\n",
    "                        print(f\"Processed {idx + 1}/{len(chunk_data)} chunks\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error extracting features from chunk {idx}: {e}\")\n",
    "                    continue\n",
    "        else:\n",
    "            # Bez chunkingu - použijeme celé soubory\n",
    "            features_list = []\n",
    "            valid_labels = []\n",
    "            \n",
    "            print(\"\\nExtracting features from full audio files...\")\n",
    "            for audio_file, label in zip(audio_files, labels):\n",
    "                try:\n",
    "                    features = self.feature_extractor.extract_features(audio_file)\n",
    "                    features_list.append(features)\n",
    "                    valid_labels.append(label)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {audio_file}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Převod na DataFrame\n",
    "        df = pd.DataFrame(features_list)\n",
    "        X = df.values\n",
    "        y = np.array(valid_labels)\n",
    "        \n",
    "        print(f\"\\nFinal dataset size: {X.shape[0]} samples with {X.shape[1]} features\")\n",
    "        \n",
    "        return X, y, df.columns\n",
    "    \n",
    "    def train(self, X, y, feature_names):\n",
    "        \"\"\"\n",
    "        Trénuje model\n",
    "        \n",
    "        Args:\n",
    "            X: feature matrix\n",
    "            y: labels\n",
    "            feature_names: názvy features\n",
    "        \"\"\"\n",
    "        # Rozdělení dat\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42, stratify=y\n",
    "        )\n",
    "\n",
    "        # Škálování features\n",
    "        X_train_scaled = self.scaler.fit_transform(X_train)\n",
    "        X_test_scaled = self.scaler.transform(X_test)\n",
    "\n",
    "        # Trénování modelu\n",
    "        if self.model_type == 'xgboost':\n",
    "            self.model = xgb.XGBClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=5,\n",
    "                learning_rate=0.1,\n",
    "                objective='multi:softmax',\n",
    "                num_class=self.n_classes,\n",
    "                random_state=42\n",
    "            )\n",
    "        else:\n",
    "            self.model = GradientBoostingClassifier(\n",
    "                n_estimators=100,\n",
    "                max_depth=20,\n",
    "                learning_rate=0.1,\n",
    "                random_state=42\n",
    "            )\n",
    "        \n",
    "        self.model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluace\n",
    "        y_pred = self.model.predict(X_test_scaled)\n",
    "        \n",
    "        target_names = [\n",
    "            'distance_ok',\n",
    "            'distance_too_close',\n",
    "            'distance_too_far',\n",
    "            'gain_ok',\n",
    "            'gain_too_high',\n",
    "            'gain_too_low',\n",
    "            'mic_coondenser',\n",
    "            'mic_dynamic',\n",
    "            'noise_bad',\n",
    "            'noise_ok',\n",
    "            'space_studio',\n",
    "            'space_with_reverb'\n",
    "        ][:self.n_classes]\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=target_names))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=target_names, yticklabels=target_names)\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Cross-validation\n",
    "        cv_scores = cross_val_score(self.model, X_train_scaled, y_train, cv=5)\n",
    "        print(f\"\\nCross-validation accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std() * 2:.3f})\")\n",
    "        \n",
    "        # Feature importance\n",
    "        importance = self.model.feature_importances_\n",
    "            \n",
    "        self.feature_importance = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'importance': importance\n",
    "        }).sort_values('importance', ascending=False)\n",
    "        \n",
    "        return self.model, self.feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cb47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = AudioDistanceClassifier(model_type='xgboost', n_classes=4)\n",
    "feedback = classifier.get_interpretable_feedback('test_audio.wav')\n",
    "print(f\"\\nPredikce: {feedback['prediction']}\")\n",
    "print(f\"Jistota: {feedback['confidence']:.1f}%\")\n",
    "print(\"\\nDoporučení:\")\n",
    "for rec in feedback['recommendations']:\n",
    "    print(f\"  • {rec}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
